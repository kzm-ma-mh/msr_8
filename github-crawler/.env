# ─────────────────────────────────────────────
# GitHub Configuration
# ─────────────────────────────────────────────
GITHUB_TOKEN=*****


# ─────────────────────────────────────────────
# Gitea Configuration
# ─────────────────────────────────────────────
GITEA_URL=http://localhost:3000
GITEA_TOKEN=******

# ─────────────────────────────────────────────
# Search Configuration
# ─────────────────────────────────────────────
# کلیدواژه‌ها (با کاما جدا شوند)
SEARCH_KEYWORDS=machine-learning

# زبان برنامه‌نویسی
SEARCH_LANGUAGE=python

# حداقل تعداد ستاره
MIN_STARS=10

# ─── تعداد پروژه نهایی برای هر کلیدواژه ───
# این تعداد، پروژه‌هایی است که تمام شرایط را دارند
# (README + Issue + PR + Code)
# چون بعضی پروژه‌ها رد می‌شوند، کرولر بیشتر بررسی می‌کند
PROJECTS_PER_KEYWORD=1

# حداکثر تعداد مخازنی که برای رسیدن به عدد بالا بررسی می‌شوند
# مثلاً اگر 20 پروژه واجد شرایط بخواهید، شاید 100 تا بررسی شود
MAX_SCAN_PER_KEYWORD=5

# ─────────────────────────────────────────────
# Extraction Limits
# ─────────────────────────────────────────────
# حداقل تعداد هر نوع داده برای قبول شدن مخزن
MIN_ISSUES_REQUIRED=3
MIN_PRS_REQUIRED=2
MIN_CODE_FILES_REQUIRED=3

# حداکثر تعداد استخراج از هر نوع
MAX_ISSUES_EXTRACT=50
MAX_PRS_EXTRACT=30
MAX_CODE_FILES_EXTRACT=25

# پسوند فایل‌های کد مجاز
CODE_EXTENSIONS=.py,.js,.ts,.go,.rs,.java,.cpp,.c,.rb

# ─────────────────────────────────────────────
# Scheduler
# ─────────────────────────────────────────────
CRON_INTERVAL_HOURS=6

# ─────────────────────────────────────────────
# Logging & Database
# ─────────────────────────────────────────────
LOG_LEVEL=INFO
LOG_FILE=data/crawler.log
DB_PATH=data/repositories.db


# ─── تنظیم جدید: Organization مقصد ───
GITEA_ORG=github-mirror